{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tidying Up Your Data</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most common things you will do with pandas involves tidying your\n",
    "data, which is the process of preparing raw data for analysis. Showing you how to use\n",
    "various features of pandas to get raw data into a tidy form is the focus of this chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas, numpy and datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Set some pandas options for controlling output\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Working with missing data</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is “missing” in pandas when it has a value of NaN (also seen as np.nan—the form\n",
    "from NumPy). The NaN value represents that in a particular Series that there is not a value\n",
    "specified for the particular index label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   c1  c2  c3\n",
       "a   0   1   2\n",
       "b   3   4   5\n",
       "c   6   7   8\n",
       "d   9  10  11\n",
       "e  12  13  14"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame with 5 rows and 3 columns\n",
    "df = pd.DataFrame(np.arange(0, 15).reshape(5, 3), \n",
    "index=['a', 'b', 'c', 'd', 'e'],\n",
    "columns=['c1', 'c2', 'c3'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2],\n",
       "       [ 3,  4,  5],\n",
       "       [ 6,  7,  8],\n",
       "       [ 9, 10, 11],\n",
       "       [12, 13, 14]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0, 15).reshape(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0   NaN NaN\n",
       "c   6.0   7.0   8.0   NaN NaN\n",
       "d   9.0  10.0  11.0   NaN NaN\n",
       "e  12.0  13.0  14.0   NaN NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN\n",
       "g   NaN   NaN   NaN   NaN NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add some columns and rows to the DataFrame\n",
    "# column c4 with NaN values\n",
    "df['c4'] = np.nan\n",
    "\n",
    "# row 'f' with 15 through 18\n",
    "df.loc['f'] = np.arange(15, 19)\n",
    "\n",
    "# row 'g' will all NaN\n",
    "df.loc['g'] = np.nan\n",
    "\n",
    "# column 'C5' with NaN's\n",
    "df['c5'] = np.nan\n",
    "\n",
    "# change value in col 'c4' row 'a'\n",
    "df['c4']['a'] = 20\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This DataFrame object exhibits the following characteristics that will support most of the\n",
    "examples that follow in this section:\n",
    "<ul>\n",
    "    <li>One row consisting only of NaN values</li>\n",
    "    <li>One column is consisiting only of NaN values</li>\n",
    "    <li>Several rows and columns consisting of both numeric values and NaN values</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Determining NaN values in Series and DataFrame\n",
    "objects</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NaN values in a DataFrame object can be identified using the .isnull() method. Any\n",
    "True value means that the item is a NaN value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      c1     c2     c3     c4    c5\n",
       "a  False  False  False  False  True\n",
       "b  False  False  False   True  True\n",
       "c  False  False  False   True  True\n",
       "d  False  False  False   True  True\n",
       "e  False  False  False   True  True\n",
       "f  False  False  False  False  True\n",
       "g   True   True   True   True  True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which items are NaN?\n",
    "df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the fact that the .sum() method treats True as 1 and False as 0 to determine\n",
    "the number of NaN values in a DataFrame object. By applying .sum() on the result of\n",
    ".isnull(), we will get a total for the number of True values (representing NaN values) in\n",
    "each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c1    1\n",
       "c2    1\n",
       "c3    1\n",
       "c4    5\n",
       "c5    7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of NaN values in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying .sum() to the resulting series gives the total number of NaN values in the original\n",
    "DataFrame object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total count of NaN values\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to determine this is to use the .count() method of a Series object and\n",
    "DataFrame. For a Series method, this method will return the number of non-NaN values.\n",
    "For a DataFrame object, it will count the number of non-NaN values in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c1    6\n",
       "c2    6\n",
       "c3    6\n",
       "c4    2\n",
       "c5    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of non-NaN values in each column\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0   NaN NaN\n",
       "c   6.0   7.0   8.0   NaN NaN\n",
       "d   9.0  10.0  11.0   NaN NaN\n",
       "e  12.0  13.0  14.0   NaN NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN\n",
       "g   NaN   NaN   NaN   NaN NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This then needs to be flipped around to sum the number of NaN values, which can be\n",
    "calculated as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and this counts the number of NaN values too\n",
    "(len(df) - df.count()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c1    6\n",
       "c2    6\n",
       "c3    6\n",
       "c4    2\n",
       "c5    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c1    1\n",
       "c2    1\n",
       "c3    1\n",
       "c4    5\n",
       "c5    7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df) - df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also determine whether an item is not NaN using the .notnull() method, which\n",
    "returns True if the value is not a NaN value, otherwise it returns False:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      c1     c2     c3     c4     c5\n",
       "a   True   True   True   True  False\n",
       "b   True   True   True  False  False\n",
       "c   True   True   True  False  False\n",
       "d   True   True   True  False  False\n",
       "e   True   True   True  False  False\n",
       "f   True   True   True   True  False\n",
       "g  False  False  False  False  False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which items are not null?\n",
    "df.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0   NaN NaN\n",
       "c   6.0   7.0   8.0   NaN NaN\n",
       "d   9.0  10.0  11.0   NaN NaN\n",
       "e  12.0  13.0  14.0   NaN NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN\n",
       "g   NaN   NaN   NaN   NaN NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c1    6\n",
       "c2    6\n",
       "c3    6\n",
       "c4    2\n",
       "c5    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.notnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Selecting out or dropping missing data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0   NaN NaN\n",
       "c   6.0   7.0   8.0   NaN NaN\n",
       "d   9.0  10.0  11.0   NaN NaN\n",
       "e  12.0  13.0  14.0   NaN NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN\n",
       "g   NaN   NaN   NaN   NaN NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     True\n",
       "b    False\n",
       "c    False\n",
       "d    False\n",
       "e    False\n",
       "f     True\n",
       "g    False\n",
       "Name: c4, dtype: bool"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.c4.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "f    18.0\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the non-NaN items in column c4\n",
    "df.c4[df.c4.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas also provides a convenience function .dropna(), which will drop the items in a\n",
    "Series where the value is NaN, involving less typing than the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "f    18.0\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .dropna will also return non NaN values\n",
    "# this gets all non NaN items in column c4\n",
    "df.c4.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0   NaN NaN\n",
       "c   6.0   7.0   8.0   NaN NaN\n",
       "d   9.0  10.0  11.0   NaN NaN\n",
       "e  12.0  13.0  14.0   NaN NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN\n",
       "g   NaN   NaN   NaN   NaN NaN"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b     NaN\n",
       "c     NaN\n",
       "d     NaN\n",
       "e     NaN\n",
       "f    18.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropna returns a copy with the values dropped\n",
    "# the source DataFrame / column is not changed\n",
    "df.c4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that .dropna() has actually returned a copy of DataFrame without the rows. The\n",
    "original DataFrame is not changed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When applied to a DataFrame object, .dropna() will drop all rows from a DataFrame\n",
    "object that have at least one NaN value. The following code demonstrates this in action,\n",
    "and since each row has at least one NaN value, ,<b>there are no rows in the result:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [c1, c2, c3, c4, c5]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on a DataFrame this will drop entire rows\n",
    "# where there is at least one NaN\n",
    "# in this case, that is all rows\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to only drop rows where all values are NaN, you can use the how='all'\n",
    "parameter. The following code only drops the g row since it has all NaN values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0   NaN NaN\n",
       "c   6.0   7.0   8.0   NaN NaN\n",
       "d   9.0  10.0  11.0   NaN NaN\n",
       "e  12.0  13.0  14.0   NaN NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as NaN will be dropped\n",
    "df.dropna(how = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be applied to the columns instead of the rows, by changing the axis\n",
    "parameter to axis=1. The following code drops the c5 column as it is the only one with all\n",
    "NaN values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4\n",
       "a   0.0   1.0   2.0  20.0\n",
       "b   3.0   4.0   5.0   NaN\n",
       "c   6.0   7.0   8.0   NaN\n",
       "d   9.0  10.0  11.0   NaN\n",
       "e  12.0  13.0  14.0   NaN\n",
       "f  15.0  16.0  17.0  18.0\n",
       "g   NaN   NaN   NaN   NaN"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flip to drop columns instead of rows\n",
    "df.dropna(how='all', axis=1) # say goodbye to c5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of df\n",
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace two NaN cells with values\n",
    "df2.loc['g'].c1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0   NaN NaN\n",
       "c   6.0   7.0   8.0   NaN NaN\n",
       "d   9.0  10.0  11.0   NaN NaN\n",
       "e  12.0  13.0  14.0   NaN NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN\n",
       "g   0.0   NaN   NaN   NaN NaN"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0   NaN NaN\n",
       "c   6.0   7.0   8.0   NaN NaN\n",
       "d   9.0  10.0  11.0   NaN NaN\n",
       "e  12.0  13.0  14.0   NaN NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN\n",
       "g   0.0   NaN   0.0   NaN NaN"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc['g'].c3 = 0\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c3\n",
       "a   0.0   2.0\n",
       "b   3.0   5.0\n",
       "c   6.0   8.0\n",
       "d   9.0  11.0\n",
       "e  12.0  14.0\n",
       "f  15.0  17.0\n",
       "g   0.0   0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now drop columns with any NaN values\n",
    "df2.dropna(how='any', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .dropna() methods also has a parameter, thresh, which when given an integer value\n",
    "specifies the minimum number of NaN values that must exist before the drop is performed.\n",
    "The following code drops all columns with at least five NaN values; these are the c4 and c5\n",
    "columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3\n",
       "a   0.0   1.0   2.0\n",
       "b   3.0   4.0   5.0\n",
       "c   6.0   7.0   8.0\n",
       "d   9.0  10.0  11.0\n",
       "e  12.0  13.0  14.0\n",
       "f  15.0  16.0  17.0\n",
       "g   NaN   NaN   NaN"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only drop columns with at least 5 NaN values\n",
    "df.dropna(thresh=5, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the .dropna() method (and the Boolean selection) returns a copy of the\n",
    "DataFrame object, and the data is dropped from that copy. If you want to drop the data in\n",
    "the actual DataFrame, use the inplace=True parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>How pandas handles NaN values in mathematical\n",
    "operations</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NaN values are handled differently in pandas than in NumPy. This is demonstrated\n",
    "using the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nan, 2.0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a NumPy array with one NaN value\n",
    "a = np.array([1, 2, np.nan, 3])\n",
    "\n",
    "# create a Series from the array\n",
    "s = pd.Series(a)\n",
    "\n",
    "# the mean of each is different\n",
    "a.mean(), s.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy functions, when encountering a NaN value, will return NaN. pandas functions and\n",
    "will typically ignore the NaN values and continue processing the function as though the\n",
    "values were not part of the Series object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More specifically, the way that pandas handles NaN values is as follows:\n",
    "<ul><li>Summing of data treats NaN as 0</li>\n",
    "    <li>If all values are NaN, the result is NaN</li>\n",
    "<li>Methods like .cumsum() and .cumprod() ignore NaN values, but preserve them in the\n",
    "    resulting arrays</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0   NaN NaN\n",
       "c   6.0   7.0   8.0   NaN NaN\n",
       "d   9.0  10.0  11.0   NaN NaN\n",
       "e  12.0  13.0  14.0   NaN NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN\n",
       "g   NaN   NaN   NaN   NaN NaN"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate sum, mean and cumsum handling of NaN\n",
    "# get one column\n",
    "s = df.c4\n",
    "s.sum() # NaN values treated as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.mean() # NaN also treated as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b     NaN\n",
       "c     NaN\n",
       "d     NaN\n",
       "e     NaN\n",
       "f    38.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as 0 in the cumsum, but NaN values preserved in result Series\n",
    "s.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    21.0\n",
       "b     NaN\n",
       "c     NaN\n",
       "d     NaN\n",
       "e     NaN\n",
       "f    19.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in arithmetic, a NaN value will result in NaN\n",
    "df.c4 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Filling in missing data</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you prefer to replace the NaN values with a specific value, instead of having them\n",
    "propagated or flat out ignored, you can use the .fillna() method. The following code\n",
    "fills the NaN values with 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4   c5\n",
       "a   0.0   1.0   2.0  20.0  0.0\n",
       "b   3.0   4.0   5.0   0.0  0.0\n",
       "c   6.0   7.0   8.0   0.0  0.0\n",
       "d   9.0  10.0  11.0   0.0  0.0\n",
       "e  12.0  13.0  14.0   0.0  0.0\n",
       "f  15.0  16.0  17.0  18.0  0.0\n",
       "g   0.0   0.0   0.0   0.0  0.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return a new DataFrame with NaN values filled with 0\n",
    "filled = df.fillna(0)\n",
    "filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be aware that this causes differences in the resulting values. As an example, the following\n",
    "code shows the result of applying the .mean() method to the DataFrame object with the\n",
    "NaN values, as compared to the DataFrame that has its NaN values filled with 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c1     7.5\n",
       "c2     8.5\n",
       "c3     9.5\n",
       "c4    19.0\n",
       "c5     NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NaNs don't count as an item in calculating\n",
    "# the means\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c1    6.428571\n",
       "c2    7.285714\n",
       "c3    8.142857\n",
       "c4    5.428571\n",
       "c5    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# having replaced NaN with 0 can make\n",
    "# operations such as mean have different results\n",
    "filled.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to limit the number of times that the data will be filled using the limit\n",
    "parameter. Each time the NaN values are identified, pandas will fill the NaN values with the\n",
    "previous value up to the limit times in each group of NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4   c5\n",
       "a   0.0   1.0   2.0  20.0  0.0\n",
       "b   3.0   4.0   5.0   0.0  0.0\n",
       "c   6.0   7.0   8.0   0.0  NaN\n",
       "d   9.0  10.0  11.0   NaN  NaN\n",
       "e  12.0  13.0  14.0   NaN  NaN\n",
       "f  15.0  16.0  17.0  18.0  NaN\n",
       "g   0.0   0.0   0.0   NaN  NaN"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only fills the first two NaN values in each row with 0\n",
    "df.fillna(0, limit=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Forward and backward filling of missing values</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaps in data can be filled by propagating non-NaN values forward or backward along a\n",
    "Series. To demonstrate this, the following example will “fill forward” the c4 column of\n",
    "DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b     NaN\n",
       "c     NaN\n",
       "d     NaN\n",
       "e     NaN\n",
       "f    18.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.c4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b    20.0\n",
       "c    20.0\n",
       "d    20.0\n",
       "e    20.0\n",
       "f    18.0\n",
       "g    18.0\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the c4 column and fill NaNs forward\n",
    "df.c4.fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b    18.0\n",
       "c    18.0\n",
       "d    18.0\n",
       "e    18.0\n",
       "f    18.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform a backwards fill\n",
    "df.c4.fillna(method=\"bfill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save a little typing, pandas also has global level functions pd.ffill() and pd.bfill(),\n",
    "which are equivalent to .fillna(method=\"ffill\") and .fillna(method=\"bfill\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b     NaN\n",
       "c     NaN\n",
       "d     NaN\n",
       "e     NaN\n",
       "f    18.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.c4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b    18.0\n",
       "c    18.0\n",
       "d    18.0\n",
       "e    18.0\n",
       "f    18.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.c4.bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b    20.0\n",
       "c    20.0\n",
       "d    20.0\n",
       "e    20.0\n",
       "f    18.0\n",
       "g    18.0\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.c4.ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Filling using index labels</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can be filled using the labels of a Series or keys of a Python dictionary. This allows\n",
    "you to specify different fill values for different elements based upon the value of the index\n",
    "label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    100\n",
       "e    101\n",
       "g    102\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new Series of values to be\n",
    "# used to fill NaN values where the index label matches\n",
    "fill_values = pd.Series([100, 101, 102], index=['a', 'e', 'g'])\n",
    "fill_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b     NaN\n",
       "c     NaN\n",
       "d     NaN\n",
       "e     NaN\n",
       "f    18.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.c4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     20.0\n",
       "b      NaN\n",
       "c      NaN\n",
       "d      NaN\n",
       "e    101.0\n",
       "f     18.0\n",
       "g    102.0\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using c4, fill using fill_values\n",
    "# a, e and g will be filled with matching values only if they are NaN\n",
    "df.c4.fillna(fill_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common scenario, is to fill all the NaN values in a column with the mean of the\n",
    "column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0   NaN NaN\n",
       "c   6.0   7.0   8.0   NaN NaN\n",
       "d   9.0  10.0  11.0   NaN NaN\n",
       "e  12.0  13.0  14.0   NaN NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN\n",
       "g   NaN   NaN   NaN   NaN NaN"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     c1    c2    c3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0  19.0 NaN\n",
       "c   6.0   7.0   8.0  19.0 NaN\n",
       "d   9.0  10.0  11.0  19.0 NaN\n",
       "e  12.0  13.0  14.0  19.0 NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN\n",
       "g   7.5   8.5   9.5  19.0 NaN"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill NaN values in each column with the\n",
    "# mean of the values in that column\n",
    "df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Interpolation of missing values</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both DataFrame and Series have an .interpolate() method that will, by default,\n",
    "perform a linear interpolation of missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.00\n",
       "1    1.25\n",
       "2    1.50\n",
       "3    1.75\n",
       "4    2.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear interpolate the NaN values from 1 through 2\n",
    "s = pd.Series([1, np.nan, np.nan, np.nan, 2])\n",
    "s.interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interpolation method also has the ability to specify a specific method of interpolation.\n",
    "One of the common methods is to use time-based interpolation. Consider the following\n",
    "Series of dates and values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014-01-01    1.0\n",
       "2014-02-01    NaN\n",
       "2014-04-01    2.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a time series, but missing one date in the Series\n",
    "ts = pd.Series([1, np.nan, 2], index=[datetime.datetime(2014, 1, 1),\n",
    "datetime.datetime(2014, 2, 1), datetime.datetime(2014, 4, 1)])\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014-01-01    1.0\n",
       "2014-02-01    1.5\n",
       "2014-04-01    2.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear interpolate based on the number of items in the Series\n",
    "ts.interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The value for 2014-02-01 is calculated as 1.0 + (2.0-1.0)/2 = 1.5, since there is one NaN\n",
    "value between the values 2.0 and 1.0.</p>\n",
    "<p>The important thing to note is that the series is missing an entry for 2014-03-01. If we\n",
    "were expecting to interpolate daily values, there would be two values calculated, one for\n",
    "2014-02-01 and another for 2014-03-01, resulting in one more value in the numerator of\n",
    "the interpolation.</p>\n",
    "<p>This can be corrected by specifying the method of interpolation as “time“:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014-01-01    1.000000\n",
       "2014-02-01    1.344444\n",
       "2014-04-01    2.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this accounts for the fact that we don't have\n",
    "# an entry for 2014-03-01\n",
    "ts.interpolate(method=\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the correct interpolation for 2014-02-01 based upon dates. Also note that the index\n",
    "label and value for 2014-03-01 is not added to the Series, it is just factored into the\n",
    "interpolation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolation can also be specified to calculate values relative to the index values when\n",
    "using numeric index labels. To demonstrate this, we will use the following Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1       NaN\n",
       "10    100.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a Series to demonstrate index label based interpolation\n",
    "s = pd.Series([0, np.nan, 100], index=[0, 1, 10])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we perform a linear interpolation, we get the following value for label 1, which is\n",
    "correct for a linear interpolation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1      50.0\n",
       "10    100.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear interpolate\n",
    "s.interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, what if we want to interpolate the value to be relative to the index value? To do\n",
    "this, we can use method=\"values\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1      10.0\n",
       "10    100.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interpolate based upon the values in the index\n",
    "s.interpolate(method=\"values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the value calculated for NaN is interpolated using relative positioning based upon the\n",
    "labels in the index. The NaN value has a label of 1, which is one tenth of the way between 0\n",
    "and 10, so the interpolated value will be 0 + (100-0)/10, or 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Handing duplicate data</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To facilitate finding duplicate data, pandas provides a .duplicates() method that returns\n",
    "a Boolean Series where each entry represents whether or not the row is a duplicate. A\n",
    "True value represents that the specific row has appeared earlier in the DataFrame object\n",
    "with all column values being identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b\n",
       "0  x  1\n",
       "1  x  1\n",
       "2  x  2\n",
       "3  y  3\n",
       "4  y  3\n",
       "5  y  4\n",
       "6  y  4"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a DataFrame with lots of duplicate data\n",
    "data = pd.DataFrame({'a': ['x'] * 3 + ['y'] * 4,\n",
    "'b': [1, 1, 2, 3, 3, 4, 4]})\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2    False\n",
       "3    False\n",
       "4     True\n",
       "5    False\n",
       "6     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reports which rows are duplicates based upon\n",
    "# if the data in all columns was seen before\n",
    "data.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Duplicate rows can be dropped from a DataFrame using the .drop_duplicates() method.\n",
    "This method will return a copy of the DataFrame object with the duplicate rows removed.</p> <p>It is also possible to use the inplace=True parameter to remove the rows without making\n",
    "a copy:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b\n",
       "0  x  1\n",
       "2  x  2\n",
       "3  y  3\n",
       "5  y  4"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicate rows retaining first row of the duplicates\n",
    "data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Note that there is a ramification to which indexes remain when dropping duplicates. The\n",
    "duplicate records may have different index labels (labels are not taken into account in\n",
    "calculating a duplicate). So, which row is kept can affect the set of labels in the resulting\n",
    "DataFrame object.</p><p>The default operation is to keep the first row of the duplicates. If you want to keep the last\n",
    "row of duplicates, you can use the take_last=True parameter. The following code\n",
    "demonstrates how the result differs using this parameter:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b\n",
       "0  x  1\n",
       "2  x  2\n",
       "3  y  3\n",
       "5  y  4"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicate rows, only keeping the first\n",
    "# instance of any data\n",
    "data.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to check for duplicates based on a smaller set of columns, you can specify a\n",
    "list of columns names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "5    False\n",
       "6    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a column c with values 0..6\n",
    "# this makes .duplicated() report no duplicate rows\n",
    "data['c'] = range(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b  c\n",
       "0  x  1  0\n",
       "1  x  1  1\n",
       "2  x  2  2\n",
       "3  y  3  3\n",
       "4  y  3  4\n",
       "5  y  4  5\n",
       "6  y  4  6"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "5    False\n",
       "6    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b  c\n",
       "0  x  1  0\n",
       "2  x  2  2\n",
       "3  y  3  3\n",
       "5  y  4  5"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but if we specify duplicates to be dropped only in columns a & b\n",
    "# they will be dropped\n",
    "data.drop_duplicates(['a', 'b'], keep=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Transforming Data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Mapping</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the basic tasks in data transformations is mapping of a set of values to another set.\n",
    "pandas provides a generic ability to map values using a lookup table (via a Python\n",
    "dictionary or a pandas Series) using the .map() method. This method performs the\n",
    "mapping by matching the values of the outer Series with the index labels of the inner\n",
    "Series, and returning a new Series with the index labels of the outer Series but the\n",
    "values from the inner Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(one      1\n",
       " two      2\n",
       " three    3\n",
       " dtype: int64,\n",
       " 1    a\n",
       " 2    b\n",
       " 3    c\n",
       " dtype: object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create two Series objects to demonstrate mapping\n",
    "x = pd.Series({\"one\": 1, \"two\": 2, \"three\": 3})\n",
    "y = pd.Series({1: \"a\", 2: \"b\", 3: \"c\"})\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one      a\n",
       "two      b\n",
       "three    c\n",
       "dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map values in x to values in y\n",
    "x.map(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like with other alignment operations, if pandas does not find a map between the value of\n",
    "the outer Series and an index label of the inner Series, it will fill the value with NaN. To\n",
    "demonstrate this, the following code removes the 3 key from the outer Series, therefore\n",
    "causing the alignment to fail for that record, and the result is that a NaN value is\n",
    "introduced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one        a\n",
       "two        b\n",
       "three    NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# three in x will not align / map to a value in y\n",
    "x = pd.Series({\"one\": 1, \"two\": 2, \"three\": 3})\n",
    "y = pd.Series({1: \"a\", 2: \"b\"})\n",
    "x.map(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Replacing Values</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We previously saw how the .fillna() method can be used to replace the NaN values with\n",
    "a value of your own decision. The .fillna() method can actually be thought of as an\n",
    "implementation of the .map() method that maps a single value, NaN, to a specific value.</p><p>\n",
    "Even more generically, the .fillna() method itself can be considered a specialization of\n",
    "a more general replacement that is provided by the .replace() method, which provides\n",
    "more flexibility by being able to replace any value (not just NaN) with another value.</p><p>\n",
    "The most basic use of the .replace() method replaces an individual value with another:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    1.0\n",
       "2    2.0\n",
       "3    3.0\n",
       "4    2.0\n",
       "5    4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a Series to demonstrate replace\n",
    "s = pd.Series([0., 1., 2., 3., 2., 4.])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    1.0\n",
       "2    5.0\n",
       "3    3.0\n",
       "4    5.0\n",
       "5    4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace all items with index label 2 with value 5\n",
    "s.replace(2, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to specify multiple items to replace and also specify their substitute\n",
    "values by passing two lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.0\n",
       "1    3.0\n",
       "2    2.0\n",
       "3    1.0\n",
       "4    2.0\n",
       "5    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace all items with new values\n",
    "s.replace([0, 1, 2, 3, 4], [4, 3, 2, 1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacement can also be performed by specifying a dictionary for lookup (a variant of the\n",
    "map process in the previous section):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     10.0\n",
       "1    100.0\n",
       "2      2.0\n",
       "3      3.0\n",
       "4      2.0\n",
       "5      4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace using entries in a dictionary\n",
    "s.replace({0: 10, 1: 100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>If using .replace() on a DataFrame, it is possible to specify different replacement values\n",
    "for each column. This is performed by passing a Python dictionary to the .replace()\n",
    "method, where the keys of the dictionary represent the names of the columns where\n",
    "replacement is to occur and the values of the dictionary are values that you want to\n",
    "replace. The second parameter to the method is the value that will be replaced where any\n",
    "matches are found.</p><p>\n",
    "The following code demonstrates by creating a DataFrame object and then replacing\n",
    "specific values in each of the columns with 100:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b\n",
       "0  0  5\n",
       "1  1  6\n",
       "2  2  7\n",
       "3  3  8\n",
       "4  4  9"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame with two columns\n",
    "df = pd.DataFrame({'a': [0, 1, 2, 3, 4], 'b': [5, 6, 7, 8, 9]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     a    b\n",
       "0    0    5\n",
       "1  100    6\n",
       "2    2    7\n",
       "3    3  100\n",
       "4    4    9"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify different replacement values for each column\n",
    "df.replace({'a': 1, 'b': 8}, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    1.0\n",
       "2    2.0\n",
       "3    3.0\n",
       "4    2.0\n",
       "5    4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10\n",
       "1     1\n",
       "2     2\n",
       "3     3\n",
       "4     4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate replacement with pad method\n",
    "# set first item to 10, to have a distinct replacement value\n",
    "s[0] = 10\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10\n",
       "1    10\n",
       "2    10\n",
       "3    10\n",
       "4     4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace items with index label 1, 2, 3, using fill from the\n",
    "# most recent value prior to the specified labels (10)\n",
    "s.replace([1, 2, 3], method='pad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Applying functions to transform data</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In situations where a direct mapping or substitution will not suffice, it is possible to apply\n",
    "a function to the data to perform an algorithm on the data. pandas provides the ability to\n",
    "apply functions to individual items, entire columns, or entire rows, providing incredible\n",
    "flexibility in transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions can be applied using the conveniently named .apply() method, which given a\n",
    "Python function, will iteratively call the function passing in each value from a Series, or\n",
    "each Series representing a DataFrame column, or a list of values representing each row in\n",
    "a DataFrame. The choice of technique to be used depends on whether the object is a\n",
    "Series or a DataFrame object, and when a DataFrame object, depending upon which axis\n",
    "is specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate applying a function to every item of a Series\n",
    "s = pd.Series(np.arange(0, 5))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    2\n",
       "2    4\n",
       "3    6\n",
       "4    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.apply(lambda v: v * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>When applying a function to items in a Series, only the value for each Series item is\n",
    "passed to the function, not the index label and the value.</p><p>When a function is applied to a DataFrame, the default is to apply the method to each\n",
    "column. pandas will iterate through all columns passing each as a Series to your function.\n",
    "The result will be a Series object with index labels matching column names and with the\n",
    "result of the function applied to the column:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a   b   c\n",
       "0  0   1   2\n",
       "1  3   4   5\n",
       "2  6   7   8\n",
       "3  9  10  11"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate applying a sum on each column\n",
    "df = pd.DataFrame(np.arange(12).reshape(4, 3),\n",
    "columns=['a', 'b', 'c'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    18\n",
       "b    22\n",
       "c    26\n",
       "dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate cumulative sum of items in each column\n",
    "df.apply(lambda col: col.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application of the function can be switched to the values from each row by specifying\n",
    "axis=1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a   b   c\n",
       "0  0   1   2\n",
       "1  3   4   5\n",
       "2  6   7   8\n",
       "3  9  10  11"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3\n",
       "1    12\n",
       "2    21\n",
       "3    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the sum of items in each row\n",
    "df.apply(lambda row: row.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>A common practice is to take the result of an apply operation and add it as a new column\n",
    "of the DataFrame. This is convenient as you can add onto the DataFrame the result of one\n",
    "or more successive calculations, providing yourself with progressive representations of the\n",
    "derivation of results through every step of the process.</p><p>The following code demonstrates this process. The first step will multiply column a by\n",
    "column b and create a new column named interim. The second step will add those values\n",
    "and column c, and create a result column with those values:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a   b   c  interim\n",
       "0  0   1   2        0\n",
       "1  3   4   5       12\n",
       "2  6   7   8       42\n",
       "3  9  10  11       90"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new column 'interim' with a * b\n",
    "df['interim'] = df.apply(lambda r: r.a * r.b, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a   b   c  interim  result\n",
       "0  0   1   2        0       2\n",
       "1  3   4   5       12      17\n",
       "2  6   7   8       42      50\n",
       "3  9  10  11       90     101"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and now a 'result' column with 'interim' + 'c'\n",
    "df['result'] = df.apply(lambda r: r.interim + r.c, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to change the values in the existing column, simply assign the result to\n",
    "an already existing column. The following code changes the ‘a‘ column values to be the\n",
    "sum of the values in the row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    a   b   c  interim  result\n",
       "0   3   1   2        0       2\n",
       "1  12   4   5       12      17\n",
       "2  21   7   8       42      50\n",
       "3  30  10  11       90     101"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace column a with the sum of columns a, b and c\n",
    "df.a = df.a + df.b + df.c\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Another point to note, is that a pandas DataFrame is not a spreadsheet where cells are\n",
    "assigned formulas and can be recalculated when cells that are referenced by the formula\n",
    "change. If you desire this to happen, you will need to execute the formulas whenever the\n",
    "dependent data changes. On the flip side, this is more efficient than with spreadsheets as\n",
    "every little change does not cause a cascade of operations to occur.</p><p>The .apply() method will always apply to the provided function to all of the items, or\n",
    "rows or columns. If you want to apply the function to a subset of these, then first perform\n",
    "a Boolean selection to filter the items you do not want process.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate this, the following code creates a DataFrame of values and inserts one NaN\n",
    "value into the second row. It then applies a function to only the rows where all values are\n",
    "not NaN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    0   1     2   3   4\n",
       "0   0   1   2.0   3   4\n",
       "1   5   6   NaN   8   9\n",
       "2  10  11  12.0  13  14"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a 3x5 DataFrame\n",
    "# only second row has a NaN\n",
    "df = pd.DataFrame(np.arange(0, 15).reshape(3,5))\n",
    "df.loc[1, 2] = np.nan\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    0   1     2   3   4\n",
       "0   0   1   2.0   3   4\n",
       "2  10  11  12.0  13  14"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10.0\n",
       "2    60.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate applying a function to only rows having\n",
    "# a count of 0 NaN values\n",
    "df.dropna().apply(lambda x: x.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last (but not least) method to apply functions that you will see in the next example is\n",
    "the .applymap() method of the DataFrame. The .apply() method was always passed an\n",
    "entire row or column. If you desire to apply a function to every individual item in the\n",
    "DataFrame one by one, then .applymap() is the method to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a practical example of using .applymap() method to every item in a DataFrame,\n",
    "and specifically to format each value to a specified number of decimal points:\n",
    "In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    0   1     2   3   4\n",
       "0   0   1   2.0   3   4\n",
       "1   5   6   NaN   8   9\n",
       "2  10  11  12.0  13  14"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       0      1      2      3      4\n",
       "0   0.00   1.00   2.00   3.00   4.00\n",
       "1   5.00   6.00    nan   8.00   9.00\n",
       "2  10.00  11.00  12.00  13.00  14.00"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use applymap to format all items of the DataFrame\n",
    "df.applymap(lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
