{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Combining and Reshaping\n",
    "Data</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter has two general categories of topics: combination and reshaping of data. The\n",
    "first two sections will cover the capabilities provided by pandas to combine the data from\n",
    "multiple pandas objects together. Combination of data in pandas is performed by\n",
    "concatenating two sets of data, where data is combined simply along either axes but\n",
    "without regard to relationships in the data. Or data can be combined using relationships in\n",
    "the data by using a pandas capability referred to as merging, which provides join\n",
    "operations that are similar to those in many relational databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining sections will examine the three primary means reshaping data in pandas.\n",
    "These will examine the processes of pivoting, stacking and unstacking, and melting of\n",
    "data. Pivoting allows us to restructure pandas data similarly to how spreadsheets pivot\n",
    "data by creating new index levels and moving data into columns based upon values (or\n",
    "vice-versa). Stacking and unstacking are similar to pivoting, but allow us to pivot data\n",
    "organized with multiple levels of indexes. And finally, melting allows us to restructure\n",
    "data into unique ID-variable-measurement combinations that are or required for many\n",
    "statistical analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, in this chapter we will examine the following concepts of combining and\n",
    "reshaping pandas data:\n",
    "<ul>\n",
    "    <li>Concatenation</li>\n",
    "<li>Merging and joining</li>\n",
    "<li>Pivots</li>\n",
    "<li>Stacking/unstacking</li>\n",
    "<li>Melting</li>\n",
    "<li>The potential performance benefits of stacked data</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas, numpy and datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Set some pandas options for controlling output\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Concatenating Data</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenation in pandas is the process of either adding rows to the end of an existing\n",
    "Series or DataFrame object or adding additional columns to a DataFrame. In pandas,\n",
    "concatenation is performed via the pandas function pd.concat(). The function will\n",
    "perform the operation on a specific axis and as we will see, will also perform any required\n",
    "set logic involved in aligning along that axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two Series objects to concatenate\n",
    "s1 = pd.Series(np.arange(0, 3))\n",
    "s2 = pd.Series(np.arange(5, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "0    5\n",
       "1    6\n",
       "2    7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate them\n",
    "pd.concat([s1, s2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two DataFrame objects can also be similarly concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two DataFrame objects to concatenate\n",
    "# using the same index labels and column names,\n",
    "# but different values\n",
    "\n",
    "df1 = pd.DataFrame(np.arange(9).reshape(3, 3), \n",
    "                   columns=['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(np.arange(9, 25).reshape(4, 4),\n",
    "                   columns=['a', 'b', 'c', 'd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   a  b  c\n",
       " 0  0  1  2\n",
       " 1  3  4  5\n",
       " 2  6  7  8,\n",
       "     a   b   c   d\n",
       " 0   9  10  11  12\n",
       " 1  13  14  15  16\n",
       " 2  17  18  19  20\n",
       " 3  21  22  23  24)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    a   b   c     d\n",
       "0   0   1   2   NaN\n",
       "1   3   4   5   NaN\n",
       "2   6   7   8   NaN\n",
       "0   9  10  11  12.0\n",
       "1  13  14  15  16.0\n",
       "2  17  18  19  20.0\n",
       "3  21  22  23  24.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do the concat\n",
    "pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The process of concatenating the two DataFrame objects will first identify the set of\n",
    "columns formed by aligning the labels in the columns, effectively determining the union\n",
    "of the column names. The resulting DataFrame object will then consist of that set of\n",
    "columns, and columns with identical names will not be duplicated.</p>\n",
    "<p>Rows will be then be added to the result, in the order of the each of the objects passed to\n",
    "pd.concat(). If a column in the result does not exist in the object being copied, NaN\n",
    "values will be filled in those locations. Duplicate row index labels can occur.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        a   b   c     d\n",
       "df1 0   0   1   2   NaN\n",
       "    1   3   4   5   NaN\n",
       "    2   6   7   8   NaN\n",
       "df2 0   9  10  11  12.0\n",
       "    1  13  14  15  16.0\n",
       "    2  17  18  19  20.0\n",
       "    3  21  22  23  24.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat the two objects, but create an index using the\n",
    "# given keys\n",
    "c = pd.concat([df1, df2], keys=['df1', 'df2'])\n",
    "# note the labeling of the rows in the output\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    a   b   c     d\n",
       "0   9  10  11  12.0\n",
       "1  13  14  15  16.0\n",
       "2  17  18  19  20.0\n",
       "3  21  22  23  24.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can extract the data originating from\n",
    "# the first or second source DataFrame\n",
    "c.loc['df2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pd.concat() function also allows you to specify the axis on which to apply the\n",
    "concatenation. The following concatenates the two DataFrame objects along the columns\n",
    "axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     a    b    c   a   b   c   d\n",
       "0  0.0  1.0  2.0   9  10  11  12\n",
       "1  3.0  4.0  5.0  13  14  15  16\n",
       "2  6.0  7.0  8.0  17  18  19  20\n",
       "3  NaN  NaN  NaN  21  22  23  24"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat df1 and df2 along columns\n",
    "# aligns on row labels, has duplicate columns\n",
    "pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the result now contains duplicate columns. The concatenation first aligns by the\n",
    "row index labels of each DataFrame object, and then fills in the columns from the first\n",
    "DataFrame object and then the second. The columns are not aligned and result in duplicate\n",
    "values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same rules of alignment and filling of NaN values apply in this case, except that they\n",
    "are applied to the rowsâ€™ index labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>A concatenation of two or more DataFrame objects actually performs an outer join\n",
    "operation along the index labels on the axis opposite to the one specified. This makes the\n",
    "result of the concatenation similar to having performed a union of those index labels, and\n",
    "then data is filled based on the alignment of those labels to the source objects.</p>\n",
    "<p>The type of join can be changed to an inner join and can be performed by specifying\n",
    "join='inner' as the parameter. The inner join then logically performs an intersection\n",
    "instead of a union. The following demonstrates this.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  df1       df2            \n",
       "    a  b  c   a   b   c   d\n",
       "0   0  1  2   9  10  11  12\n",
       "1   3  4  5  13  14  15  16\n",
       "2   6  7  8  17  18  19  20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do an inner join instead of outer\n",
    "# results in one row\n",
    "df = pd.concat([df1, df2], axis=1, join='inner', keys=['df1','df2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     a    b    c   a   b   c   d\n",
       "0  0.0  1.0  2.0   9  10  11  12\n",
       "1  3.0  4.0  5.0  13  14  15  16\n",
       "2  6.0  7.0  8.0  17  18  19  20\n",
       "3  NaN  NaN  NaN  21  22  23  24"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VS Outer join\n",
    "pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    a   b   c   d\n",
       "0   9  10  11  12\n",
       "1  13  14  15  16\n",
       "2  17  18  19  20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve the data that originated from the\n",
    "# DataFrame with key 'df2'\n",
    "df['df2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DataFrame (and Series) object also contains an .append() method, which will\n",
    "concatenate the two specified DataFrame objects along the row index labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    a   b   c     d\n",
       "0   0   1   2   NaN\n",
       "1   3   4   5   NaN\n",
       "2   6   7   8   NaN\n",
       "0   9  10  11  12.0\n",
       "1  13  14  15  16.0\n",
       "2  17  18  19  20.0\n",
       "3  21  22  23  24.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# append does a concatenate along axis=0\n",
    "# duplicate row index labels can result\n",
    "df1.append(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with a concatenation on axis=1, the index labels in the rows are copied without\n",
    "consideration of the creation of duplicates, and the columns labels are joined in a manner\n",
    "which ensures no duplicate column name is included in the result. If you would like to\n",
    "ensure that the resulting index does not have duplicates but preserves all of the rows, you\n",
    "can use the ignore_index=True parameter. This essentially returns the same result except\n",
    "with new Int64Index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    a   b   c     d\n",
       "0   0   1   2   NaN\n",
       "1   3   4   5   NaN\n",
       "2   6   7   8   NaN\n",
       "3   9  10  11  12.0\n",
       "4  13  14  15  16.0\n",
       "5  17  18  19  20.0\n",
       "6  21  22  23  24.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove duplicates in the result index by ignoring the\n",
    "# index labels in the source DataFrame objects\n",
    "df1.append(df2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Merging and joining data</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas allows the merging of pandas objects with database-like join operations using the\n",
    "pd.merge() function and the .merge() method of a DataFrame object. These joins are\n",
    "high performance and are performed in memory. A merge combines the data of two\n",
    "pandas objects by finding matching values in one or more columns or row indexes. It then\n",
    "returns a new object that represents a combination of the data from both based on\n",
    "relational-database-like join semantics applied to those values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merges are useful as they allow us to model a single DataFrame for each type of data (one\n",
    "of the rules of having tidy data) but to be able to relate data in different DataFrame objects\n",
    "using values existing in both sets of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>An overview of merges</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate this in pandas, we will use the following two DataFrame\n",
    "objects, where one represents a list of customer details, and the other represents the orders\n",
    "made by customers and what day the order was made. They will be related to each other\n",
    "using the CustomerID columns in each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   CustomerID    Name             Address\n",
       "0          10    Mike    Address for Mike\n",
       "1          11  Marcia  Address for Marcia"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers = {'CustomerID': [10, 11],\n",
    "             'Name'      : ['Mike', 'Marcia'],\n",
    "             'Address'   : ['Address for Mike', 'Address for Marcia']}\n",
    "\n",
    "customers = pd.DataFrame(customers)\n",
    "customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   CustomerID   OrderDate\n",
       "0          10  2014-12-01\n",
       "1          11  2014-12-01\n",
       "2          10  2014-12-01"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders = {'CustomerID': [10, 11, 10],\n",
    "          'OrderDate':  [datetime.date(2014, 12, 1),\n",
    "                         datetime.date(2014, 12, 1),\n",
    "                         datetime.date(2014, 12, 1)\n",
    "                        ]\n",
    "         }\n",
    "\n",
    "orders = pd.DataFrame(orders)\n",
    "orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   CustomerID    Name             Address   OrderDate\n",
       "0          10    Mike    Address for Mike  2014-12-01\n",
       "1          10    Mike    Address for Mike  2014-12-01\n",
       "2          11  Marcia  Address for Marcia  2014-12-01"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge customers and orders so we can ship the items\n",
    "customers.merge(orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>To be even more detailed, what pandas has specifically done is the following:</p>\n",
    "<ol>\n",
    "    <li>Determines the columns in both customers and orders with common labels. These\n",
    "        columns are treated as the keys to perform the join.</li>\n",
    "<li>It creates a new DataFrame whose columns are the labels from the keys identified in\n",
    "step 1, followed by all of the non-key labels from both objects.</li>\n",
    "<li>It matches values in the key columns of both DataFrame objects.</li>\n",
    "<li>It then creates a row in the result for each set of matching labels.</li>\n",
    "<li>It then copies the data from those matching rows from each source object into that\n",
    "respective row and columns of the result.</li>\n",
    "<li>It assigns a new Int64Index to the result.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explicitly specify which column use to relate the objects, use the on parameter. The\n",
    "following performs a merge using only the values in the key1 column of both DataFrame\n",
    "objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  key1 key2  lval1\n",
       " 0    a    x      0\n",
       " 1    b    y      1\n",
       " 2    c    z      2,\n",
       "   key1 key2  rval1\n",
       " 1    a    x      6\n",
       " 2    b    a      7\n",
       " 3    c    z      8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_data = {'key1': ['a', 'b', 'c'],\n",
    "             'key2': ['x', 'y', 'z'],\n",
    "            'lval1': [ 0, 1, 2]}\n",
    "\n",
    "right_data = {'key1': ['a', 'b', 'c'],\n",
    "              'key2': ['x', 'a', 'z'],\n",
    "              'rval1': [ 6, 7, 8 ]}\n",
    "\n",
    "left = pd.DataFrame(left_data, index=[0, 1, 2])\n",
    "right = pd.DataFrame(right_data, index=[1, 2, 3])\n",
    "left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1 key2  lval1  rval1\n",
       "0    a    x      0      6\n",
       "1    c    z      2      8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate merge without specifying columns to merge\n",
    "# this will implicitly merge on all common columns\n",
    "left.merge(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1 key2_x  lval1 key2_y  rval1\n",
       "0    a      x      0      x      6\n",
       "1    b      y      1      a      7\n",
       "2    c      z      2      z      8"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate merge using an explicit column\n",
    "# on needs the value to be in both DataFrame objects\n",
    "left.merge(right, on='key1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Comparing this result to the previous example, as only the values in the key1 column were\n",
    "used to relate the data in the two objects, the result now has three rows as there are\n",
    "matching a, b, and c values in that single column of both objects.</p>\n",
    "<p>The on parameter can also be given a list of column names. The following reverts to using\n",
    "both the key1 and key2 columns, resulting in being identical the earlier example where\n",
    "those two columns where implicitly identified by pandas:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1 key2  lval1  rval1\n",
       "0    a    x      0      6\n",
       "1    c    z      2      8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge explicitly using two columns\n",
    "left.merge(right, on=['key1', 'key2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The columns specified with on need to exist in both DataFrame objects. If you would like\n",
    "to merge based on columns with different names in each object, you can use the left_on\n",
    "and right_on parameters, passing the name or names of columns to each respective\n",
    "parameter.</p><p>To perform a merge with the labels of the row indexes of the two DataFrame objects, use\n",
    "the left_index=True and right_index=True parameters (both need to be specified):</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  key1 key2  lval1\n",
       " 0    a    x      0\n",
       " 1    b    y      1\n",
       " 2    c    z      2,\n",
       "   key1 key2  rval1\n",
       " 1    a    x      6\n",
       " 2    b    a      7\n",
       " 3    c    z      8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left,right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1_x key2_x  lval1 key1_y key2_y  rval1\n",
       "1      b      y      1      a      x      6\n",
       "2      c      z      2      b      a      7"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join on the row indices of both matrices\n",
    "pd.merge(left, right, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This has identified that the index labels in common are 1 and 2, so the resulting DataFrame\n",
    "has two rows with these values and labels in the index. pandas then creates a column in\n",
    "the result for every column in both objects and then copies the values.</p><p>\n",
    "As both DataFrame objects had a column with an identical name, key, the columns in the\n",
    "result have the _x and _y suffixes appended to them to identify the DataFrame they\n",
    "originated from. _x is for left and _y for right. You can specify these suffixes using the\n",
    "suffixes parameter and passing a two-item sequence.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Specifying the join semantics of a merge operation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default type of join performed by pd.merge() is an inner join. To use another join\n",
    "method, the method of join to be used can be specified using the how parameter of the\n",
    "pd.merge() function (or the .merge() method). The valid options are:\n",
    "\n",
    "<ul>\n",
    "    <li>inner: This is the intersection of keys from both DataFrame objects</li>\n",
    "<li>outer: This is the union of keys from both DataFrame objects</li>\n",
    "<li>left: This only uses keys from the left DataFrame</li>\n",
    "<li>right: This only uses keys from the right DataFrame</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  key1 key2  lval1\n",
       " 0    a    x      0\n",
       " 1    b    y      1\n",
       " 2    c    z      2,\n",
       "   key1 key2  rval1\n",
       " 1    a    x      6\n",
       " 2    b    a      7\n",
       " 3    c    z      8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left,right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1 key2  lval1  rval1\n",
       "0    a    x    0.0    6.0\n",
       "1    b    y    1.0    NaN\n",
       "2    c    z    2.0    8.0\n",
       "3    b    a    NaN    7.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outer join, merges all matched data,\n",
    "# and fills unmatched items with NaN\n",
    "left.merge(right, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  key1 key2  lval1\n",
       " 0    a    x      0\n",
       " 1    b    y      1\n",
       " 2    c    z      2,\n",
       "   key1 key2  rval1\n",
       " 1    a    x      6\n",
       " 2    b    a      7\n",
       " 3    c    z      8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left,right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1 key2  lval1  rval1\n",
       "0    a    x      0    6.0\n",
       "1    b    y      1    NaN\n",
       "2    c    z      2    8.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# left join, merges all matched data, and only fills unmatched\n",
    "# items from the left dataframe with NaN filled for the\n",
    "# unmatched items in the result\n",
    "# rows with labels 0 and 2\n",
    "# match on key1 and key2 the row with label 1 is from left\n",
    "left.merge(right, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  key1 key2  lval1\n",
       " 0    a    x      0\n",
       " 1    b    y      1\n",
       " 2    c    z      2,\n",
       "   key1 key2  rval1\n",
       " 1    a    x      6\n",
       " 2    b    a      7\n",
       " 3    c    z      8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left,right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1 key2  lval1  rval1\n",
       "0    a    x    0.0      6\n",
       "1    c    z    2.0      8\n",
       "2    b    a    NaN      7"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# right join, merges all matched data, and only fills unmatched\n",
    "# item from the right with NaN filled for the unmatched items\n",
    "# in the result\n",
    "# rows with labels 0 and 1 match on key1 and key2\n",
    "# the row with label 2 is from right\n",
    "left.merge(right, how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas library also provides a .join() method that can be used to perform a join\n",
    "using the index labels of the two DataFrame objects (instead of values in columns). Note\n",
    "that if the columns in the two DataFrame objects do not have unique column names, you\n",
    "must specify suffixes using the lsuffix and rsuffix parameters (automatic suffixing is\n",
    "not performed). The following code demonstrates both the join and specification of\n",
    "suffixes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1_left key2_left  lval1 key1_right key2_right  rval1\n",
       "0         a         x      0        NaN        NaN    NaN\n",
       "1         b         y      1          a          x    6.0\n",
       "2         c         z      2          b          a    7.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join left with right (default method is outer)\n",
    "# and since these DataFrame objects have duplicate column names\n",
    "# we just specify lsuffix and rsuffix\n",
    "left.join(right, lsuffix='_left', rsuffix='_right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default type of join performed is an outer join. Note that this differs from the default\n",
    "of the .merge() method, which defaults to inner. To change to an inner join, specify\n",
    "how='inner', as is demonstrated in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  key1_left key2_left  lval1 key1_right key2_right  rval1\n",
       "1         b         y      1          a          x      6\n",
       "2         c         z      2          b          a      7"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join left with right with an inner join\n",
    "left.join(right, lsuffix='_left', rsuffix='_right', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Notice that this is roughly equivalent to the earlier result from In[29] except with the\n",
    "result having columns with slightly different names.</p><p>\n",
    "It is also possible to perform right and left joins, but they lead to results similar to previous\n",
    "examples, so they will be omitted for brevity.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pivoting</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Data is often stored in a stacked format, which is also referred to as record format; this is\n",
    "common in databases, .csv files, and Excel spreadsheets. In a stacked format, the data is\n",
    "often not normalized and has repeated values in many columns, or values that should\n",
    "logically exists in other tables (violating another concept of tidy data).</p><p>Take the following data, which represents a stream of data from an accelerometer on a\n",
    "mobile device (provided with the data from the sample code):</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    interval axis  reading\n",
       "0          0    X      0.0\n",
       "1          0    Y      0.5\n",
       "2          0    Z      1.0\n",
       "3          1    X      0.1\n",
       "4          1    Y      0.4\n",
       "..       ...  ...      ...\n",
       "7          2    Y      0.8\n",
       "8          2    Z      0.3\n",
       "9          3    X      0.2\n",
       "10         3    Y      0.7\n",
       "11         3    Z      0.2\n",
       "\n",
       "[12 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in accellerometer data\n",
    "sensor_readings = pd.read_csv(\"data/accel.csv\")\n",
    "sensor_readings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An issue with this data as it is organized is: how does one go about determining the\n",
    "readings for a specific axis? This can be naively done with Boolean selections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   interval axis  reading\n",
       "0         0    X      0.0\n",
       "3         1    X      0.1\n",
       "6         2    X      0.3\n",
       "9         3    X      0.2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract X-axis readings\n",
    "sensor_readings[sensor_readings['axis'] == 'X']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>An issue here is what if you want to know the values for all axes at a given time, not just\n",
    "the x axis? You can perform a selection for each value of the axis, but that is repetitive\n",
    "code and does not handle the scenario of new axis values being inserted into DataFrame\n",
    "without a change to the code.</p><p>A better representation would be where columns represent the unique variable values. To\n",
    "convert to this form, use the DataFrame objectsâ€™ .pivot() function:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    interval axis  reading\n",
       "0          0    X      0.0\n",
       "1          0    Y      0.5\n",
       "2          0    Z      1.0\n",
       "3          1    X      0.1\n",
       "4          1    Y      0.4\n",
       "..       ...  ...      ...\n",
       "7          2    Y      0.8\n",
       "8          2    Z      0.3\n",
       "9          3    X      0.2\n",
       "10         3    Y      0.7\n",
       "11         3    Z      0.2\n",
       "\n",
       "[12 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "axis        X    Y    Z\n",
       "interval               \n",
       "0         0.0  0.5  1.0\n",
       "1         0.1  0.4  0.2\n",
       "2         0.3  0.8  0.3\n",
       "3         0.2  0.7  0.2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pivot the data. Interval becomes the index, the columns are\n",
    "# the current axes values, and use the readings as values\n",
    "sensor_readings.pivot(index='interval',\n",
    "columns='axis',\n",
    "values='reading')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has taken all of the distinct values from the axis column, and pivoted them into\n",
    "columns on the new DataFrame, while filling in values for the new columns from the\n",
    "appropriate rows and columns of the original DataFrame. This new DataFrame\n",
    "demonstrates that it is now very easy to identify the X, Y and Z sensor readings at each time\n",
    "interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Example that applies in the next chapter of Stacking...</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interval  axis\n",
       "0         X       0.0\n",
       "          Y       0.5\n",
       "          Z       1.0\n",
       "1         X       0.1\n",
       "          Y       0.4\n",
       "                 ... \n",
       "2         Y       0.8\n",
       "          Z       0.3\n",
       "3         X       0.2\n",
       "          Y       0.7\n",
       "          Z       0.2\n",
       "Length: 12, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ak =sensor_readings.pivot(index='interval',\n",
    "columns='axis',\n",
    "values='reading')\n",
    "ak.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Stacking and unstacking</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Similar to the pivot function are the .stack() and .unstack() methods that are part of\n",
    "both Series and DataFrame objects. The process of stacking pivots a level of column\n",
    "labels to the row index. Unstacking performs the opposite, pivoting a level of the row\n",
    "index into the column index</p><p>One of the differences between stacking/unstacking and performing a pivot is that unlike\n",
    "pivots the stack and unstack functions will be able to pivot specific levels of a hierarchical\n",
    "index. Also, where a pivot retains the same number of levels on an index, a stack and\n",
    "unstack will always increase the levels on the index of one of the axes (columns for\n",
    "unstack and rows for stack) and decrease the levels on the other axis.</p><p>The reasons for stacking and unstacking are along the same lines as for performing pivots.\n",
    "Fundamentally it comes down to how you want your data organized for analysis. The\n",
    "organization can change the means and ease of retrieving data and deriving results. As will\n",
    "be demonstrated it also can have significant performance ramifications.</p><p>To understand the process of stacking and unstacking, we will first look at simpler cases\n",
    "using nonhierarchical indexes, with very simple data, and focus on stacking. We then\n",
    "progress to more complicated data using hierarchical indexes, revisiting the sensor data we\n",
    "saw previously in the chapter and focusing on unstacking.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     a\n",
       "one  1\n",
       "two  2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple DataFrame with one column\n",
    "df = pd.DataFrame({'a': [1, 2]}, index={'one', 'two'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one    1\n",
       "two    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple Series\n",
    "ser = pd.Series([1, 2], index={'one', 'two'})\n",
    "ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking will move one level of the columns index into a new level of the rows index. As\n",
    "our DataFrame only has one level, this collapses a DataFrame object into a Series object\n",
    "with a hierarchical row index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one  a    1\n",
       "two  a    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# push the column to another level of the index\n",
    "# the result is a Series where values are looked up through\n",
    "# a multi-index\n",
    "stacked1 = df.stack()\n",
    "stacked1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('one', 'a'),\n",
       "            ('two', 'a')],\n",
       "           )"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked1.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access values, we now need to pass a tuple to the indexer of the Series object, which\n",
    "does the lookup with just the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lookup one / a using just the index via a tuple\n",
    "stacked1[('one', 'a')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If DataFrame contains multiple columns, then all of the columns are moved to the same\n",
    "additional level of the new Series object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     a  b\n",
       "one  1  3\n",
       "two  2  4"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame with two columns\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': [3, 4]},\n",
    "index={'one', 'two'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one  a    1\n",
       "     b    3\n",
       "two  a    2\n",
       "     b    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# push the two columns into a single level of the index\n",
    "stacked2 = df.stack()\n",
    "stacked2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lookup value with index of one / b\n",
    "stacked2[('one', 'b')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unstacking will perform a similar operation in the opposite direction by moving a level of\n",
    "the row index into a level of the columns axis. We will examine this process in the next\n",
    "section as unstacking generally assumes that the index being unstacked is hierarchical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one  a    1\n",
       "     b    3\n",
       "two  a    2\n",
       "     b    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     a  b\n",
       "one  1  3\n",
       "two  2  4"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked2.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Unstacking using hierarchical indexes</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate unstacking with hierarchical indexes we will revisit the sensor data we\n",
    "saw earlier in the chapter. However, we will add in an additional column to the\n",
    "measurement data that represents readings for multiple users and copy data for two users.\n",
    "The following sets up this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    interval axis  reading   who\n",
       " 0          0    X      0.0  Mike\n",
       " 1          0    Y      0.5  Mike\n",
       " 2          0    Z      1.0  Mike\n",
       " 3          1    X      0.1  Mike\n",
       " 4          1    Y      0.4  Mike\n",
       " ..       ...  ...      ...   ...\n",
       " 7          2    Y      0.8  Mike\n",
       " 8          2    Z      0.3  Mike\n",
       " 9          3    X      0.2  Mike\n",
       " 10         3    Y      0.7  Mike\n",
       " 11         3    Z      0.2  Mike\n",
       " \n",
       " [12 rows x 4 columns],\n",
       "     interval axis  reading     who\n",
       " 0          0    X      0.0  Mikael\n",
       " 1          0    Y      0.5  Mikael\n",
       " 2          0    Z      1.0  Mikael\n",
       " 3          1    X      0.1  Mikael\n",
       " 4          1    Y      0.4  Mikael\n",
       " ..       ...  ...      ...     ...\n",
       " 7          2    Y      0.8  Mikael\n",
       " 8          2    Z      0.3  Mikael\n",
       " 9          3    X      0.2  Mikael\n",
       " 10         3    Y      0.7  Mikael\n",
       " 11         3    Z      0.2  Mikael\n",
       " \n",
       " [12 rows x 4 columns])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make two copies of the sensor data, one for each user\n",
    "user1 = sensor_readings.copy()\n",
    "user2 = sensor_readings.copy()\n",
    "\n",
    "# add names to the two copies\n",
    "user1['who'] = 'Mike'\n",
    "user2['who'] = 'Mikael'\n",
    "\n",
    "user1,user2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    interval axis  reading     who\n",
       "0          0    X      0.0  Mikael\n",
       "1          0    Y     50.0  Mikael\n",
       "2          0    Z    100.0  Mikael\n",
       "3          1    X     10.0  Mikael\n",
       "4          1    Y     40.0  Mikael\n",
       "..       ...  ...      ...     ...\n",
       "7          2    Y     80.0  Mikael\n",
       "8          2    Z     30.0  Mikael\n",
       "9          3    X     20.0  Mikael\n",
       "10         3    Y     70.0  Mikael\n",
       "11         3    Z     20.0  Mikael\n",
       "\n",
       "[12 rows x 4 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for demonstration, let's scale user2's readings\n",
    "user2['reading'] *= 100\n",
    "user2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    interval axis  reading     who\n",
       "0          0    X      0.0    Mike\n",
       "1          0    Y      0.5    Mike\n",
       "2          0    Z      1.0    Mike\n",
       "3          1    X      0.1    Mike\n",
       "4          1    Y      0.4    Mike\n",
       "..       ...  ...      ...     ...\n",
       "7          2    Y     80.0  Mikael\n",
       "8          2    Z     30.0  Mikael\n",
       "9          3    X     20.0  Mikael\n",
       "10         3    Y     70.0  Mikael\n",
       "11         3    Z     20.0  Mikael\n",
       "\n",
       "[24 rows x 4 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and reorganize this to have a hierarchical row index\n",
    "ak = multi_user_sensor_data = pd.concat([user1, user2])\n",
    "ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                      reading\n",
       "who    interval axis         \n",
       "Mike   0        X         0.0\n",
       "                Y         0.5\n",
       "                Z         1.0\n",
       "       1        X         0.1\n",
       "                Y         0.4\n",
       "...                       ...\n",
       "Mikael 2        Y        80.0\n",
       "                Z        30.0\n",
       "       3        X        20.0\n",
       "                Y        70.0\n",
       "                Z        20.0\n",
       "\n",
       "[24 rows x 1 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_user_sensor_data = ak.set_index(['who', 'interval', 'axis'])\n",
    "multi_user_sensor_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this organization in the data we can do things such as examine all the readings for a\n",
    "specific person using just the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               reading\n",
       "interval axis         \n",
       "0        X         0.0\n",
       "         Y         0.5\n",
       "         Z         1.0\n",
       "1        X         0.1\n",
       "         Y         0.4\n",
       "...                ...\n",
       "2        Y         0.8\n",
       "         Z         0.3\n",
       "3        X         0.2\n",
       "         Y         0.7\n",
       "         Z         0.2\n",
       "\n",
       "[12 rows x 1 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up user data for Mike using just the index\n",
    "multi_user_sensor_data.loc['Mike']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or get all the readings of all axes and for all users at interval 1 using .xs()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             reading\n",
       "who    axis         \n",
       "Mike   X         0.1\n",
       "       Y         0.4\n",
       "       Z         0.2\n",
       "Mikael X        10.0\n",
       "       Y        40.0\n",
       "       Z        20.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# readings for all users and axes at interval 1\n",
    "multi_user_sensor_data.xs(1, level='interval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unstacking will move the last level of the row index into a new level of the columns index\n",
    "resulting in columns having MultiIndex. The following demonstrates the last level of this\n",
    "unstacking (the axis level of the index):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                      reading\n",
       "who    interval axis         \n",
       "Mike   0        X         0.0\n",
       "                Y         0.5\n",
       "                Z         1.0\n",
       "       1        X         0.1\n",
       "                Y         0.4\n",
       "...                       ...\n",
       "Mikael 2        Y        80.0\n",
       "                Z        30.0\n",
       "       3        X        20.0\n",
       "                Y        70.0\n",
       "                Z        20.0\n",
       "\n",
       "[24 rows x 1 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_user_sensor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                reading             \n",
       "axis                  X     Y      Z\n",
       "who    interval                     \n",
       "Mikael 0            0.0  50.0  100.0\n",
       "       1           10.0  40.0   20.0\n",
       "       2           30.0  80.0   30.0\n",
       "       3           20.0  70.0   20.0\n",
       "Mike   0            0.0   0.5    1.0\n",
       "       1            0.1   0.4    0.2\n",
       "       2            0.3   0.8    0.3\n",
       "       3            0.2   0.7    0.2"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unstack axis\n",
    "multi_user_sensor_data.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         reading                          ...                               \n",
       "axis           X                       Y  ...            Z                  \n",
       "interval       0     1     2     3     0  ...     3      0     1     2     3\n",
       "who                                       ...                               \n",
       "Mikael       0.0  10.0  30.0  20.0  50.0  ...  70.0  100.0  20.0  30.0  20.0\n",
       "Mike         0.0   0.1   0.3   0.2   0.5  ...   0.7    1.0   0.2   0.3   0.2\n",
       "\n",
       "[2 rows x 12 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unstack axis\n",
    "multi_user_sensor_data.unstack().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         axis  interval  who   \n",
       "reading  X     0         Mikael     0.0\n",
       "                         Mike       0.0\n",
       "               1         Mikael    10.0\n",
       "                         Mike       0.1\n",
       "               2         Mikael    30.0\n",
       "                                   ... \n",
       "         Z     1         Mike       0.2\n",
       "               2         Mikael    30.0\n",
       "                         Mike       0.3\n",
       "               3         Mikael    20.0\n",
       "                         Mike       0.2\n",
       "Length: 24, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unstack axis\n",
    "multi_user_sensor_data.unstack().unstack().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To unstack a different level use the level parameter. The following code unstacks the first\n",
    "level (level=0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                      reading\n",
       "who    interval axis         \n",
       "Mike   0        X         0.0\n",
       "                Y         0.5\n",
       "                Z         1.0\n",
       "       1        X         0.1\n",
       "                Y         0.4\n",
       "...                       ...\n",
       "Mikael 2        Y        80.0\n",
       "                Z        30.0\n",
       "       3        X        20.0\n",
       "                Y        70.0\n",
       "                Z        20.0\n",
       "\n",
       "[24 rows x 1 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_user_sensor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              reading     \n",
       "who            Mikael Mike\n",
       "interval axis             \n",
       "0        X        0.0  0.0\n",
       "         Y       50.0  0.5\n",
       "         Z      100.0  1.0\n",
       "1        X       10.0  0.1\n",
       "         Y       40.0  0.4\n",
       "...               ...  ...\n",
       "2        Y       80.0  0.8\n",
       "         Z       30.0  0.3\n",
       "3        X       20.0  0.2\n",
       "         Y       70.0  0.7\n",
       "         Z       20.0  0.2\n",
       "\n",
       "[12 rows x 2 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unstack at level=0\n",
    "multi_user_sensor_data.unstack(level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple levels can be unstacked simultaneously by passing a list of the levels to\n",
    ".unstack(). Additionally, if the levels are named, they can be specified by name instead\n",
    "of location. The following unstacks the who and axis levels by name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         reading                              \n",
       "who         Mike           Mikael             \n",
       "axis           X    Y    Z      X     Y      Z\n",
       "interval                                      \n",
       "0            0.0  0.5  1.0    0.0  50.0  100.0\n",
       "1            0.1  0.4  0.2   10.0  40.0   20.0\n",
       "2            0.3  0.8  0.3   30.0  80.0   30.0\n",
       "3            0.2  0.7  0.2   20.0  70.0   20.0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unstack who and axis levels\n",
    "unstacked = multi_user_sensor_data.unstack(['who', 'axis'])\n",
    "unstacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be thorough, we can restack this data. The following code will stack the who level of\n",
    "the column back into the row index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                reading             \n",
       "axis                  X     Y      Z\n",
       "interval who                        \n",
       "0        Mikael     0.0  50.0  100.0\n",
       "         Mike       0.0   0.5    1.0\n",
       "1        Mikael    10.0  40.0   20.0\n",
       "         Mike       0.1   0.4    0.2\n",
       "2        Mikael    30.0  80.0   30.0\n",
       "         Mike       0.3   0.8    0.3\n",
       "3        Mikael    20.0  70.0   20.0\n",
       "         Mike       0.2   0.7    0.2"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and we can of course stack what we have unstacked\n",
    "# this re-stacks who\n",
    "unstacked.stack(level='who')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>There are a couple of things worth pointing out about this result. First, stacking and\n",
    "unstacking always move the levels into the last levels of the other index. Notice that the\n",
    "who level is now the last level of the row index, but started out earlier as the first level.</p><p>This would have ramifications on the code to access elements via that index as it has\n",
    "changed to another level. If you want to put a level back into another position you will\n",
    "need to reorganize the indexes with other means than stacking and unstacking.</p><p>Second, with all this moving around of data, stacking and unstacking (as well as pivoting)\n",
    "do not lose any information. They simply change the means by which it is organized and\n",
    "accessed.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Melting</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Melting is a type of unpivoting, and is often referred to as changing a DataFrame object\n",
    "from wide format to long format. This format is common in various statistical analyses,\n",
    "and data you read may be provided already in a melted form, or you may need to pass data\n",
    "in this format to other code that expects this organization.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically, melting is the process of reshaping a DataFrame into a format where two or\n",
    "more columns, referred to as variable and value, are created by unpivoting column\n",
    "labels in the variable column, and then moving the data from these columns into the\n",
    "appropriate location in the value column. All other columns are then made into identifier\n",
    "columns that assist in describing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     Name  Height  Weight  Age\n",
       "0    Mike     6.1     220   23\n",
       "1  Mikael     6.0     185   28"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will demonstrate melting with this DataFrame\n",
    "data = pd.DataFrame({'Name' : ['Mike', 'Mikael'], 'Height' : [6.1, 6.0], 'Weight' : [220, 185], 'Age': [23, 28]})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following melts this DataFrame, using the Name column as the identifier column, and\n",
    "the Height and Weight columns as measured variables. The Name column remains, with\n",
    "the Height and Weight columns unpivoted into the variable column. Then the values\n",
    "from these two columns are rearranged into the value column, and ensured to align with\n",
    "the appropriate combination values of Name and variable that would have existed in the\n",
    "original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     Name variable  value\n",
       "0    Mike   Height    6.1\n",
       "1  Mikael   Height    6.0\n",
       "2    Mike   Weight  220.0\n",
       "3  Mikael   Weight  185.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# melt it, use Name as the id,\n",
    "# Height and Weight columns as the variables\n",
    "pd.melt(data, id_vars=['Name'], value_vars=['Height', 'Weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now restructured so that it is easy to extract the value for any combination of\n",
    "variable and Name. Additionally, when in this format it is easier to add a new variable and\n",
    "measurement as the data can simply be added as a new row instead of requiring a change\n",
    "of structure to DataFrame by adding a new column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Performance benefits of stacked data</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will examine a reason for which we would want to stack data like this. This is\n",
    "because it can be shown to be more efficient than using lookup through a single level\n",
    "index and then a column lookup, or even compared to an .iloc lookup, specifying the\n",
    "location of the row and column by location. The following demonstrates this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time the different methods\n",
    "import timeit\n",
    "\n",
    "t = timeit.Timer(\"stacked1[('one', 'a')]\", \"from __main__ import stacked1, df\")\n",
    "r1 = timeit.timeit(lambda: stacked1.loc[('one', 'a')], number=10000)\n",
    "r2 = timeit.timeit(lambda: df.loc['one']['a'], number=10000)\n",
    "r3 = timeit.timeit(lambda: df.iloc[1, 0], number=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.44381511099709314, 1.311863232000178, 0.08189404600125272)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and the results areâ€¦ Yes, it's the fastest of the three\n",
    "r1, r2, r3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can have extreme benefits for application performance if we need to repeatedly\n",
    "access a large number of scalar values out of a DataFrame."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
